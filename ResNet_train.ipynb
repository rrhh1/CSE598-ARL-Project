{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2a73f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a27efe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 5\n",
    "BATCH_SIZE = 10\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "47cb676f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[279.0000, 217.0000,   9.3409],\n",
       "         [279.0000, 217.0000,   9.3409],\n",
       "         [279.0000, 217.0000,   9.3409],\n",
       "         ...,\n",
       "         [279.0000, 217.0000,   9.3409],\n",
       "         [282.0000, 169.0000,   9.4869],\n",
       "         [282.0000, 169.0000,   9.4869]],\n",
       "\n",
       "        [[359.0000, 319.0000,  37.6564],\n",
       "         [274.0000, 189.0000,   8.8601],\n",
       "         [274.0000, 189.0000,   8.8601],\n",
       "         ...,\n",
       "         [279.0000, 149.0000,   8.7322],\n",
       "         [279.0000, 149.0000,   8.7322],\n",
       "         [279.0000, 149.0000,   8.7322]],\n",
       "\n",
       "        [[306.0000, 430.0000,  39.2427],\n",
       "         [267.0000, 213.0000,   8.8601],\n",
       "         [267.0000, 213.0000,   8.8601],\n",
       "         ...,\n",
       "         [268.0000, 193.0000,   8.8601],\n",
       "         [268.0000, 193.0000,   8.8601],\n",
       "         [268.0000, 193.0000,   8.8601]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[396.0000,  22.0000,  11.9270],\n",
       "         [291.0000, 209.0000,   7.9058],\n",
       "         [291.0000, 209.0000,   7.9058],\n",
       "         ...,\n",
       "         [293.0000, 189.0000,   8.0778],\n",
       "         [293.0000, 189.0000,   8.0778],\n",
       "         [293.0000, 189.0000,   8.0778]],\n",
       "\n",
       "        [[450.0000, 248.0000,  81.9177],\n",
       "         [272.0000, 199.0000,   8.7322],\n",
       "         [272.0000, 199.0000,   8.7322],\n",
       "         ...,\n",
       "         [274.0000, 157.0000,   8.5441],\n",
       "         [274.0000, 157.0000,   8.5441],\n",
       "         [274.0000, 157.0000,   8.5441]],\n",
       "\n",
       "        [[117.0000, 437.0000,  34.0772],\n",
       "         [273.0000, 218.0000,   7.9058],\n",
       "         [273.0000, 218.0000,   7.9058],\n",
       "         ...,\n",
       "         [275.0000, 176.0000,   8.8601],\n",
       "         [275.0000, 176.0000,   8.8601],\n",
       "         [275.0000, 176.0000,   8.8601]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"new_dataset.csv\")\n",
    "data_target = np.asarray(df[[\"data\", \"target\"]])\n",
    "np.random.shuffle(data_target)\n",
    "\n",
    "train_X = data_target[:75, 0]\n",
    "train_y = data_target[:75, 1]\n",
    "\n",
    "valid_X = data_target[75:, 0]\n",
    "valid_y = data_target[75:, 1]\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    train_X[i] = np.asarray(ast.literal_eval(train_X[i]))\n",
    "\n",
    "for i in range(valid_X.shape[0]):\n",
    "    valid_X[i] = np.asarray(ast.literal_eval(valid_X[i]))\n",
    "\n",
    "train_X = np.array([x for x in train_X])\n",
    "train_y = np.asarray(train_y, dtype=np.int16)\n",
    "\n",
    "valid_X = np.array([x for x in valid_X])\n",
    "valid_y = np.asarray(valid_y, dtype=np.int16)\n",
    "\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_y = torch.from_numpy(train_y).long()\n",
    "valid_X = torch.from_numpy(valid_X).float()\n",
    "valid_y = torch.from_numpy(valid_y).long()\n",
    "\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0e377cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        x = torch.Tensor(self.x[index])\n",
    "        y = torch.Tensor(self.y[index])\n",
    "\n",
    "        return (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        count = self.x.shape[0]\n",
    "        return count\n",
    "\n",
    "train_dataset = CustomDataset(train_X, train_y)\n",
    "valid_dataset = CustomDataset(valid_X, valid_y)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec8c18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dropout = 0.5\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(10, 4098),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "\n",
    "            nn.Linear(4098, 16392),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "\n",
    "            nn.Linear(16392, 50176),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(50176, 16392),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "\n",
    "            nn.Linear(16392, 4098),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "\n",
    "            nn.Linear(4098, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        x = self.decoder(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.decoder(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "775049b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m auto_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mAutoEncoder\u001b[49m()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(auto_encoder\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AutoEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "auto_encoder = AutoEncoder().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(auto_encoder.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    auto_encoder.train()\n",
    "    for i, datum in enumerate(train_dataloader):\n",
    "        inputs, labels = datum[0].to(device), datum[0].to(device).clone().detach()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = auto_encoder(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    auto_encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, datum in enumerate(valid_dataloader):\n",
    "            inputs, labels = datum[0].to(device), datum[0].to(device).clone().detach()\n",
    "\n",
    "            outputs = auto_encoder(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader.sampler)\n",
    "    avg_valid_loss = valid_loss / len(valid_dataloader.sampler)\n",
    "    \n",
    "    print(f\"=== Epoch {epoch} ===\")\n",
    "    print(f\"Average Training Loss: {avg_train_loss}\")\n",
    "    print(f\"Average Validation Loss: {avg_valid_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8220243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5d2e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modified_ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modified_ResNet, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 101)\n",
    "\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze the parameters of the last few layers for fine-tuning\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        \n",
    "        self.in_fc = nn.Linear(10, 50176)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2).to(x.device)\n",
    "        x = self.in_fc(x)\n",
    "        \n",
    "        x = x.view(-1, 3 * 224 * 224)\n",
    "        \n",
    "        min_val = torch.min(x, dim=1)[0].view(-1, 1)\n",
    "        max_val = torch.max(x, dim=1)[0].view(-1, 1)\n",
    "        x = (x - min_val) / (max_val - min_val)\n",
    "        \n",
    "        x = x.view(-1, 3, 224, 224).to(x.device)\n",
    "        x = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(x)\n",
    "\n",
    "        x = self.resnet(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bccf113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 0 ===\n",
      "Average Training Loss: 4.846560509999593\n",
      "Average Validation Loss: 4.951395511627197\n",
      "Validation Accuracy: 0.0\n",
      "=== Epoch 1 ===\n",
      "Average Training Loss: 3.856315024693807\n",
      "Average Validation Loss: 4.8973774909973145\n",
      "Validation Accuracy: 0.0\n",
      "=== Epoch 2 ===\n",
      "Average Training Loss: 3.2841781616210937\n",
      "Average Validation Loss: 4.9279398918151855\n",
      "Validation Accuracy: 0.0\n",
      "=== Epoch 3 ===\n",
      "Average Training Loss: 2.8388689359029136\n",
      "Average Validation Loss: 4.9548234939575195\n",
      "Validation Accuracy: 0.0\n",
      "=== Epoch 4 ===\n",
      "Average Training Loss: 2.5239983558654786\n",
      "Average Validation Loss: 4.889196395874023\n",
      "Validation Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Modified_ResNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, datum in enumerate(train_dataloader):\n",
    "        inputs, labels = datum[0].to(device), datum[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, datum in enumerate(valid_dataloader):\n",
    "            inputs, labels = datum[0].to(device), datum[1].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = torch.softmax(outputs, dim=1)\n",
    "            predicted = torch.argmax(predicted, dim=1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader.sampler)\n",
    "    avg_valid_loss = valid_loss / len(valid_dataloader.sampler)\n",
    "    \n",
    "    print(f\"=== Epoch {epoch} ===\")\n",
    "    print(f\"Average Training Loss: {avg_train_loss}\")\n",
    "    print(f\"Average Validation Loss: {avg_valid_loss}\")\n",
    "    print(f\"Validation Accuracy: {correct / len(valid_dataloader.sampler)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f8e3136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([38, 80, 85, 38, 38, 85, 38, 38, 53, 38], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# data = torch.tensor([[279, 231, 8.381627082824707], [279, 231, 8.381627082824707], [279, 231, 8.381627082824707], [279, 231, 8.381627082824707], [279, 231, 8.381627082824707], [279, 180, 9.34087085723877], [279, 180, 9.34087085723877], [279, 158, 9.486932754516602], [279, 158, 9.486932754516602], [279, 158, 9.486932754516602]], dtype=torch.float32)\n",
    "# data = nn.functional.normalize(data)\n",
    "\n",
    "# data = data.view(1, 10, 3).to(device)\n",
    "# output = model(data)\n",
    "\n",
    "# output = torch.softmax(output, dim=1)\n",
    "# output = torch.argmax(output, dim=1)\n",
    "# print(output.item())\n",
    "\n",
    "for datum in valid_dataloader:\n",
    "    inputs, labels = datum[0].to(device), datum[1].to(device)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    predicted = torch.softmax(outputs, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1)\n",
    "\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42a24e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Modified_ResNet.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
